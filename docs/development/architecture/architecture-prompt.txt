beschreib bitte noch was für eine rolle in unserem system die folgenden services haben:

1. UI:
   unsere ui ist das zentrale element unseres systems, mehr darüber wird im systemaufbau teil unserer doku stehen. der funktionsumfang siehe @/docs/development/architecture/systemaufbau.md
   Der Sourcecode ist hier: /Users/marc/Documents/\_coding/vue/ui

2. API:
   Die API ist unsere zentale Schnittstelle für user-generated content. In ihr werden alle Daten (außer der Chats, mehr dazu siehe matrix synapse) gespeichert. Das heißt alle angelegten Spaces, Nutzereinstellungen (wie Profildaten, ausgewähltes Theme, Gepinnte Spaces etc) und markierter Text auf Folien in Vorlesungsstreams/-aufzeichnungen können hierüber gespeichert werden. Außerdem speichern unsere AI-Agents ihre Daten von Vorlesungs-Streams dort ebenfalls. Das heißt erkannte Slides (Screenshots abgelegt in Minio, mit ihren Metadaten, zudem die Metadaten der Slides, wie Uhrzeit, Stream und Space ID, etc…) und Ergebnisse von Yolo und OCR von den Slides. Alle Daten der API werden entweder in der MongoDB oder bei Bild-Daten wie Nutzeravataren und Slide-Screenshots in der Minio gespeichert. Sämtliche live updates wie neue Slides, neue Metadaten wie Yolo oder OCR, oder Änderungen an Spaces (avatar, name,…) oder Nutzerprofilen werden per Socketio an alle aktiven Nutzer in deren UIs synchronisiert und in echtzeit aktualisiert.
   API-Docs sind hier zu finden: https://slv-api-main.cluster.hfg.gd/apidoc/
   Der Source-Code ist hier: /Users/marc/Documents/\_coding/node/slv-api

3. Matrix synapse:
   Matrix Synapse ist unser Messaging-Backend, dieses nutzen wir für unsere Chatfunktion. Alle Nachrichten und Medieninhalte aus unserem Chat werden über unseren Matrix Synapse Server gespeichert und synchronisiert. Unsere UI unterstützt volle Ende zu Ende Verschlüsselung, wobei wir standardmäßig jedoch die Schlüssel der Nutzer über unsere API synchronisieren. Dies soll für den Anfang den Nutzern die UX verbessern. Es ist jedoch für die Zukunft geplant, den Nutzern die Schlüsselverwaltung selbst zu überlassen um so vollständige echte E2E Verschlüsselung zu unterstützen.

4. Livekit:
   Livekit nutzen wir für unsere Vorlesungsstreams. Dozierende können so über unsere UI ihre Folien live an alle Zuschauer übertragen. Diese können dann auf den Folien Kommentare erstellen, welche für alle anderen Teilnehmer auf den Folien, sowie im Chat einsehbar sind (via Matrix), oder Text den sie sich merken wollen auf den Folien markieren (via API) können. Die Streams werden per API authorisiert und authentifiziert, so dass keine ungewünschten zuschauer zugriff auf die räume bekommen. Außerdem werden je nach Konfiguation AI-Agents in die Räume beitreten um die übertragenen Streams weiter zu verarbeiten. Mehr dazu siehe AI-Agents. Später soll Livekit auch noch für ein Huddle (slack) ähnliches feature verwendet werden, bisher ist aber nur die Bildschirmübertragung integriert. Über unsere Anwendung direkt ist also kein Video/Voice call möglich aktuell.

5. Minio:
   Minio nutzen wir als S3 Object Storage für die Screenshots der über unser Livekit übertragene und über unsere AI-Agents erkannten Vorlesungsslides, sowie für Space und User Avatare. Die Objekte sind dabei je nach usecase zugriffslimitiert oder mit direktlink frei einsehbar. Ein öffentlicher Zugriff auf gesamte buckets gibt es jedoch nicht

6. Keycloak:
   Keycloak ist unser zentrales Identity und Access Management System. Über Keycloak werden alle Nutzer unseres Systems verwaltet. Die UI und API sind beide an Keycloak angebunden um so eine zentrale Authentifizierung und Autorisierung zu gewährleisten. Wir nutzen es zudem für user-discovery im System, wie zum Beispiel beim Einladen von Usern in einen Channel. Unsere Backend systeme wie AI Agents sind ebenfalls über keycloak angebunden und werden dort über client authentication authentifiziert und authorisiert. Unsere API unterscheidet hierbei beispielsweise über Keycloak je nach Route, ob diese nur für clientseitige Authentifizierung (also zb AI agents) oder pkce Authentifizierung von Nutzern über unsere UI zugelassen werden.

7. MongoDB
   Unsere MongoDB ist die zentrale Datenbank für unsere API. In ihr werden alle persistenten Daten unseres Systems gespeichert, außer Mediendaten wie Bilder und Videos, welche in Minio gespeichert werden. In der MongoDB finden sich also alle Daten zu Spaces, Usern, markierten Texten auf Folien, sowie die Metadaten zu den von unseren AI-Agents erkannten Slides und deren Inhalten (OCR Texte, Yolo erkannte Objekte etc).

8. AI-Agents:
   Wir haben ein system aus ai agents, welche eine jeweilige rolle in unserem system übernehmen, welche hauptsächlich an unseren livekit server angebunden sind und die streams dessen auswerten.
   agent-coordinator: ist der zentrale agent, welcher in jeden livekit raum beitritt und dort die anderen agents koordiniert. er startet und stoppt diese je nach konfiguration und stream-aktivität.
   agent-slidechange: empfängt in jedem beigetretenen raum die bildschirmübertragungen und erkennt wenn der Dozent auf die nächste Folie wechselt. Daraufhin erstellt er via API eine Slide in der Datenbank und lädt einen Screenshot hoch. Außerdem gibt er via Livekit/Webrtc daten kanal dieses update an alle weiteren agents bekannt.
   agent-ocr: Der OCR agent wertet nach der Erkennung einer neuen Slide einen SCreenshot davon aus und erkennt alle Texte. Diese schickt er dann an die API und an den RTC Daten channel
   agent-yolo: Der Yolo Agent wertet nach Erkennung einer neuen Slide einen Screenshot davon aus und erkennt alle Objekte. Diese schickt er dann an die API und an den RTC Daten channel
   agent-summarize: Der Summatize Agent nutzt ein LLM zur zusammenfassung der erkannten slide inhalte.
   agent-stt: Der STT Agent analysiert die Audiospur des Livekit Streams und erstellt untertitel für die übertragenen Inhalte.
   Alle unsere AI Agents und deren dazugehörigen Modells hosten wir selbst auf unserem AI server, welcher über eine NVidia TEsla Karte verfügt.

Datentypen unserer Systeme finden sich hier:
/Users/marc/Documents/\_coding/node/hfgd20_types
/Users/marc/Documents/\_coding/vue/ui/src/types.d.ts

füge außerdem verlinkungen zwischen den artikeln an passenden stellen, an denen auf andere architekturbausteine verwiesen wird hinzu. wie die verlinkungen aussehen sollten siehst du in @/docs/development/architecture/index.md

an einigen stellen hab ich dir außerdem den pfad zum passenden sourcecode geschickt. schau dir diesen an wenn du fragen hast, oder stell sie mir.
